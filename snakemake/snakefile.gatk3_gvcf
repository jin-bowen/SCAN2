# vim: syntax=python

def memreq_function(wildcards, input, output, threads, resources):
    return str(int(resources.mem_mb/2) - 500) + "M"


rule gatk_genotypegvcfs:
    input:
        gvcf="gatk/hc_raw.mmq{gatk_mmq}.region_{analysis_region}.gvcf.gz"
    output:
        vcf=temp("gatk/hc_raw.mmq{gatk_mmq}.region_{analysis_region}.vcf")
    log:
        "gatk/hc_raw.mmq{gatk_mmq}.region_{analysis_region}.log"
    benchmark:
        "gatk/genotypegvcfs_benchmark.mmq{gatk_mmq}.region_{analysis_region}.tsv"
    params:
        memreq=memreq_function
    resources:
        # This likely needs to scale with number of input BAMs. ~1500MB for 5 30X BAMs
        mem_mb=4000
    shell:
        """
        gatk3 -Xmx{params.memreq} -Xms{params.memreq} \
	   -T GenotypeGVCFs \
           --dbsnp {config[dbsnp]} \
           -R {config[ref]} \
           -V {input} \
           -o {output} >& {log}
        """


# Different from the direct joint calling GATK arg files: in this case,
# join across samples in one region.
rule make_gvcf_arg_file_per_region:
    input:
        gvcfs=expand("gatk/{sample}/hc_raw.mmq{{gatk_mmq}}.region_{{analysis_region}}.gvcf.gz",
                     sample=config['bam_map'].keys())
    output:
        listfile="gatk/arg_file_gvcfs_mmq{gatk_mmq}.region_{analysis_region}.list"
    resources:
        mem_mb=100
    localrule: True
    run:
        with open(output.listfile, 'w') as f:
            for gvcf in input.gvcfs:
                f.write("--variant " + str(gvcf) + '\n')


rule gatk_combinegvcfs:
    input:
        gvcfs=expand("gatk/{sample}/hc_raw.mmq{{gatk_mmq}}.region_{{analysis_region}}.gvcf.gz",
                     sample=config['bam_map'].keys())
    output:
        gvcf="gatk/hc_raw.mmq{gatk_mmq}.region_{analysis_region}.gvcf.gz"
    log:
        "gatk/hc_raw.mmq{gatk_mmq}.region_{analysis_region}.log"
    benchmark:
        "gatk/combinegvcfs_benchmark.mmq{gatk_mmq}.region_{analysis_region}.tsv"
    params:
        infiles=lambda wildcards, input: ' '.join([ "-V " + f for f in input ]),
	memreq=memreq_function
    threads: 1
    resources:
        # This likely needs to scale with number of input BAMs.  1500MB for 5 ~30X BAMs.
        mem_mb=5000
    shell:
        """
        gatk3 -Xmx{params.memreq} -Xms{params.memreq} \
           -T CombineGVCFs \
           -R {config[ref]} \
           {params.infiles} \
           -o {output} >& {log}
        """


rule gatk_scatter:
    input:
        bam=lambda wildcards: config['bam_map'][wildcards.sample]
    output:
        gvcf="gatk/{sample}/hc_raw.mmq{gatk_mmq}.region_{analysis_region}.gvcf.gz"
    log:
        "gatk/{sample}/hc_raw.mmq{gatk_mmq}.region_{analysis_region}.log"
    benchmark:
        "gatk/{sample}/scatter_benchmark.mmq{gatk_mmq}.region_{analysis_region}.tsv"
    params:
        regionflag="-L {analysis_region}",
        mmq="{gatk_mmq}",
        # allocate half of the memory to stack, half to heap
        # it seems some JVMs allocate this memory immediately, whether used by
        # the program or not. so we subtract 1000MB (500 from stack and heap
        # each) from the total to ensure that the job isn't immediately killed
        # by the cluster scheduler.
        memreq=lambda wildcards, input, output, threads, resources: str(int(resources.mem_mb/2) - 500) + "M"
    resources:
        mem_mb=2000
    shell:
        """
        gatk3 -Xmx{params.memreq} -Xms{params.memreq} \
	    -T HaplotypeCaller \
            --dontUseSoftClippedBases -l INFO \
            --dbsnp {config[dbsnp]} \
            -mmq {params.mmq} \
            --min_base_quality_score {config[min_base_quality_score]} \
            -ERC BP_RESOLUTION \
            {params.regionflag} \
            -rf BadCigar \
            -R {config[ref]} \
            -I {input.bam} \
            -o {output.gvcf} 
        """
